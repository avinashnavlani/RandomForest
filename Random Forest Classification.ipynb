{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will be building a model on the iris flower dataset, which is a very famous classification set. It comprises sepal length, sepal width, petal length, petal width, and type of flower. There are three species or classes: setosa, versicolor, and virginia. You will build a model to classify the type of flower. The dataset is available in the scikit-learn library or you can download it from UCI Machine Learning Repository.\n",
    "\n",
    "Start by importing the datasets library from scikit-learn, and load the iris dataset with `load_iris()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Import scikit-learn dataset library\n",
    "from sklearn import datasets\n",
    "\n",
    "#Load dataset\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can print the target and feature names, to make sure you have the right dataset, as such:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['setosa' 'versicolor' 'virginica']\n",
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
     ]
    }
   ],
   "source": [
    "# print the label species(setosa, versicolor,virginica)\n",
    "print(iris.target_names)\n",
    "\n",
    "# print the names of the four features\n",
    "print(iris.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's a good idea to always explore your data a bit, so you know what you're working with. Here, you can see the first five rows of the dataset are printed, as well as the target variable for the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.1  3.5  1.4  0.2]\n",
      " [ 4.9  3.   1.4  0.2]\n",
      " [ 4.7  3.2  1.3  0.2]\n",
      " [ 4.6  3.1  1.5  0.2]\n",
      " [ 5.   3.6  1.4  0.2]]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "# print the iris data (top 5 records)\n",
    "print(iris.data[0:5])\n",
    "\n",
    "# print the iris labels (0:setosa, 1:versicolor, 2:virginica)\n",
    "print(iris.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, you can create a dataframe of iris data set in following way. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>petal length</th>\n",
       "      <th>petal width</th>\n",
       "      <th>sepal length</th>\n",
       "      <th>sepal width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   petal length  petal width  sepal length  sepal width  species\n",
       "0           1.4          0.2           5.1          3.5        0\n",
       "1           1.4          0.2           4.9          3.0        0\n",
       "2           1.3          0.2           4.7          3.2        0\n",
       "3           1.5          0.2           4.6          3.1        0\n",
       "4           1.4          0.2           5.0          3.6        0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a dataframe of given iris dataset.\n",
    "import pandas as pd\n",
    "data=pd.DataFrame({\n",
    "    'sepal length':iris.data[:,0], \n",
    "    'sepal width':iris.data[:,1], \n",
    "    'petal length':iris.data[:,2], \n",
    "    'petal width':iris.data[:,3],\n",
    "    'species':iris.target\n",
    "})\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, you separate the columns into dependent and independent variables(or features and label). Then you split those variable into train and test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import train_test_split function\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X=data[['sepal length', 'sepal width', 'petal length', 'petal width']]  # Features\n",
    "y=data['species']  \n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3) # 70% training and 30% test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After spliting, you will generate random forest model on training set and perform prediction on test set features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import Random Forest Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After model generation, check the accuracy using actual and predicted values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy:', 0.93333333333333335)\n"
     ]
    }
   ],
   "source": [
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you can also make prediciton for single individual. \n",
    "\n",
    "For example, \n",
    "\n",
    "sepal length=3 \n",
    "sepal width=5\n",
    "petal length=4 \n",
    "petal width=2\n",
    "\n",
    "Now you can predict the \"Which type of flower is?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict([[3, 5, 4, 2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, 2 indicates the flower type: 'Virginica'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Important Features in Scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, you are finding important features or selecting features in given IRIS dataset. In scikit-learn, you can perform this task in following steps:\n",
    "- First, you need to create random forest model.\n",
    "- Second, use feature importance variable to see feature importance scores.\n",
    "- Third, visualize these scores using seaborn library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import Random Forest Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "petal width (cm)     0.458607\n",
       "petal length (cm)    0.413859\n",
       "sepal length (cm)    0.103600\n",
       "sepal width (cm)     0.023933\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "feature_imp = pd.Series(clf.feature_importances_,index=iris.feature_names).sort_values(ascending=False)\n",
    "feature_imp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also visualize the feature importance. Visualization are easy to understand and interpretable. Also, visualization has highest bandwodth channel to the human brain.\n",
    "\n",
    "For visualizing you can use a combination of matplot and seaborn because seaborn built on the top of matplotlib, offers a number of customized themes  and provides additional plot types. Matplotlib is superset of seaborn and both are equally required for good visualisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAc0AAAEWCAYAAAAEvMzxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmZlZJidNMzOzTE6aZmZmmf4PtlS/WaHRO6QAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc97a470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "# Creating bar plot\n",
    "sns.barplot(x=feature_imp, y=feature_imp.index)\n",
    "# Add labels in your graph\n",
    "plt.xlabel('Feature Importance Score')\n",
    "plt.ylabel('Features')\n",
    "plt.title(\"Visualizing Important Features\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Again Generating Model on Selected Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, you can remove the feature \"sepal width\" and select remaining 3 features because it has very low importance.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import train_test_split function\n",
    "from sklearn.cross_validation import train_test_split\n",
    "# Split dataset into features and labels\n",
    "X=data[['petal length', 'petal width','sepal length']]  # Removed feature \"sepal length\"\n",
    "y=data['species']                                       \n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.70, random_state=5) # 70% training and 30% test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After spliting, you will generate random forest model on selected training set features, perform prediction on selected test set features and compare actual and predicted values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy:', 0.95238095238095233)\n"
     ]
    }
   ],
   "source": [
    "#Import Random Forest Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "# prediction on test set\n",
    "y_pred=clf.predict(X_test)\n",
    "\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you can see, after removing less important features(sepal length) accuracy got increased because it reduces misleading \n",
    "data and noise, which increases the accuracy. Also less number of important feature reduces training time."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
